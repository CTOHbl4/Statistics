{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d0db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from sem.generate_series import create_sde_process\n",
    "from sem.sem.EM import NormalMixtureEM\n",
    "from sem.sem.windows import Windows, calculate_acf\n",
    "\n",
    "class ForecastingMixin:\n",
    "    \"\"\"\n",
    "    Mixin class providing multi-step forecasting methods.\n",
    "    Models should inherit from this mixin and nn.Module.\n",
    "    \"\"\"\n",
    "    \n",
    "    def stateless_forward_multistep(self, windows: torch.Tensor, n_steps: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Autoregressive multi-step forecasting for stateless models.\n",
    "        \n",
    "        Args:\n",
    "            windows: [batch_size, window_size] - input windows\n",
    "            n_steps: number of steps to forecast\n",
    "            \n",
    "        Returns:\n",
    "            predictions: [batch_size, n_steps]\n",
    "        \"\"\"\n",
    "        forecasts = []\n",
    "        for _ in range(n_steps):\n",
    "            forecast = self.forward(windows)\n",
    "            forecasts.append(forecast)\n",
    "\n",
    "            windows = torch.cat([\n",
    "                windows[:, 1:],\n",
    "                forecast.unsqueeze(-1)\n",
    "            ], dim=1)\n",
    "        results = torch.stack(forecasts, dim=1)\n",
    "        return results\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def generate_forecast(self, idx: int, \n",
    "                         time_series: torch.Tensor,\n",
    "                         n_test_steps: int,\n",
    "                         window_size: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Generate forecast starting at given index.\n",
    "        \n",
    "        Args:\n",
    "            idx: starting index (negative values count from end)\n",
    "            time_series: full time series data\n",
    "            n_test_steps: number of steps to forecast\n",
    "            window_size: size of input window\n",
    "            train_series: alias for time_series (for backward compatibility)\n",
    "            \n",
    "        Returns:\n",
    "            predictions: forecast values\n",
    "        \"\"\"\n",
    "        if idx < 0:\n",
    "            idx = time_series.shape[-1] + idx\n",
    "        idx += 1\n",
    "\n",
    "        start_idx = idx - window_size\n",
    "        ts = time_series[..., start_idx: idx]\n",
    "        assert ts.shape[-1] == window_size, 'not enough data'\n",
    "\n",
    "        if not isinstance(ts, torch.Tensor):\n",
    "            ts = torch.tensor(ts, dtype=torch.float32)\n",
    "        if ts.dim() == 1:\n",
    "            ts = ts.unsqueeze(0)\n",
    "\n",
    "        device = next(self.parameters()).device\n",
    "        window = ts.to(device)\n",
    "\n",
    "        preds = self.forward_multistep(window, n_test_steps)\n",
    "        if ts.shape[0] == 1:\n",
    "            preds = preds.squeeze(0)\n",
    "            \n",
    "        return preds\n",
    "    \n",
    "    def get_name(self, add: str = \"\") -> str:\n",
    "        \"\"\"\n",
    "        Get model name with optional suffix.\n",
    "        \n",
    "        Args:\n",
    "            add: string to append to model name\n",
    "            \n",
    "        Returns:\n",
    "            Model class name with suffix\n",
    "        \"\"\"\n",
    "        class_name = self.__class__.__name__\n",
    "        return class_name + add\n",
    "\n",
    "    def forward_multistep(self, windows: torch.Tensor, n_steps: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Default multi-step forecasting implementation.\n",
    "        Can be overridden by subclasses for stateful models.\n",
    "        \n",
    "        Args:\n",
    "            windows: [batch_size, window_size]\n",
    "            n_steps: number of steps to forecast\n",
    "            \n",
    "        Returns:\n",
    "            predictions: [batch_size, n_steps]\n",
    "        \"\"\"\n",
    "        return self.stateless_forward_multistep(windows, n_steps)\n",
    "\n",
    "\n",
    "class EMForecaster(ForecastingMixin, nn.Module):\n",
    "    def __init__(self, \n",
    "                 window_size: int,\n",
    "                 dx_linear: bool,\n",
    "                 n_components: int = 3,\n",
    "                 hidden_dim: int = 64,\n",
    "                 n_em_iters: int = 5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dwindow_size = window_size - 1\n",
    "        self.window_size = window_size\n",
    "        self.n_components = n_components\n",
    "        negative_slope = 0.01\n",
    "        self.dx_linear = dx_linear\n",
    "\n",
    "        if dx_linear:\n",
    "            self.dx_layer = nn.Linear(self.dwindow_size, self.dwindow_size, bias=False)\n",
    "\n",
    "        self.em_layer = NormalMixtureEM(\n",
    "            series_length=self.dwindow_size,\n",
    "            n_components=n_components,\n",
    "            n_sem_iters=n_em_iters\n",
    "        )\n",
    "\n",
    "        mlp_input_dim = self.dwindow_size * (n_components)\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(mlp_input_dim, 2 * hidden_dim, bias=False),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Linear(2 * hidden_dim, n_components, bias=False)\n",
    "        )\n",
    "\n",
    "        fusion_input_dim = n_components * 5\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(fusion_input_dim, hidden_dim, bias=False),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Linear(hidden_dim, 1, bias=False)\n",
    "        )\n",
    "\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(module.weight, negative_slope)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, X_window):\n",
    "        batch_size = X_window.shape[0]\n",
    "\n",
    "        dX1 = X_window[..., 1:] - X_window[..., :-1]\n",
    "        if self.dx_linear:\n",
    "            dX1 = self.dx_layer(dX1)\n",
    "        g_ik, p_k, a_k, b_k = self.em_layer(dX1)\n",
    "\n",
    "        dX_extended = (g_ik * dX1.unsqueeze(-1)).reshape((batch_size, -1))\n",
    "\n",
    "        y_k = self.mlp(dX_extended)\n",
    "\n",
    "        attention_logits = -b_k\n",
    "        attention_weights = nn.functional.softmax(attention_logits, dim=1)\n",
    "\n",
    "        fusion_input = torch.cat([\n",
    "            y_k,\n",
    "            attention_weights * y_k,\n",
    "            a_k,\n",
    "            attention_weights * a_k,\n",
    "            p_k * a_k\n",
    "        ], dim=1)\n",
    "        forecast = X_window[..., -1] + self.fusion(fusion_input).squeeze(-1)\n",
    "        \n",
    "        return forecast\n",
    "\n",
    "\n",
    "class MLP(ForecastingMixin, nn.Module):\n",
    "    def __init__(self, window_size, hidden_dim=80):\n",
    "        super().__init__()\n",
    "        self.window_size = window_size\n",
    "        self.dwindow_size = window_size - 1\n",
    "\n",
    "        self.enrich_mlp = nn.Sequential(\n",
    "            nn.Linear(self.dwindow_size, hidden_dim, bias=False),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(hidden_dim, hidden_dim, bias=False),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(hidden_dim, hidden_dim, bias=False),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.01)\n",
    "        )\n",
    "        \n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + self.dwindow_size, hidden_dim // 2, bias=False),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(hidden_dim // 2, 1, bias=False)\n",
    "        )\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight, a=0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        dx = x[:, 1:] - x[:, :-1]\n",
    "        \n",
    "        enriched = self.enrich_mlp(dx)\n",
    "        \n",
    "        combined = torch.cat([dx, enriched], dim=1)\n",
    "        \n",
    "        delta = self.fusion(combined).squeeze(-1)\n",
    "        return x[:, -1] + delta\n",
    "\n",
    "\n",
    "class TCNForecaster(ForecastingMixin, nn.Module):\n",
    "    def __init__(self, window_size, hidden_dim=64, negative_slope=0.01):\n",
    "        super().__init__()\n",
    "        self.dwindow_size = window_size - 1\n",
    "        \n",
    "        self.dx_layer = nn.Linear(self.dwindow_size, self.dwindow_size, bias=False)\n",
    "\n",
    "        self.tcn = nn.Sequential(\n",
    "            nn.Conv1d(1, hidden_dim, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=2, dilation=2, bias=False),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=4, dilation=4, bias=False),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + self.dwindow_size, hidden_dim // 2, bias=False),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Linear(hidden_dim // 2, 1, bias=False)\n",
    "        )\n",
    "        \n",
    "        self._init_params()\n",
    "    \n",
    "    def _init_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv1d, nn.Linear)):\n",
    "                nn.init.kaiming_uniform_(m.weight, a=0.01, mode='fan_in')\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, X_window):\n",
    "        dX = X_window[:, 1:] - X_window[:, :-1]\n",
    "        dX_reshaped = dX.unsqueeze(1)\n",
    "        tcn_features = self.tcn(dX_reshaped).squeeze(-1)\n",
    "\n",
    "        combined = torch.cat([dX, tcn_features], dim=1)\n",
    "        \n",
    "        delta = self.fusion(combined).squeeze(-1)\n",
    "        return X_window[:, -1] + delta\n",
    "\n",
    "\n",
    "class LightGRU(ForecastingMixin, nn.Module):\n",
    "    def __init__(self, window_size, hidden_size=64, proj_size=32):\n",
    "        super().__init__()\n",
    "        self.window_size = window_size\n",
    "        self.dwindow_size = window_size - 1\n",
    "        \n",
    "        self.input_proj = nn.Conv1d(1, proj_size, 1, bias=False)\n",
    "        \n",
    "        self.gru = nn.GRU(\n",
    "            input_size=proj_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bias=False\n",
    "        )\n",
    "        \n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(hidden_size + self.dwindow_size, hidden_size // 2, bias=False),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(hidden_size // 2, 1, bias=False)\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for name, param in self.gru.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Linear, nn.Conv1d)):\n",
    "                nn.init.kaiming_uniform_(m.weight, a=0.01, mode='fan_in')\n",
    "    \n",
    "    def forward(self, x, hidden=None):\n",
    "\n",
    "        dx = x[:, 1:] - x[:, :-1]\n",
    "        dx_reshaped = dx.unsqueeze(1)\n",
    "        dx_proj = self.input_proj(dx_reshaped)\n",
    "        dx_proj = dx_proj.transpose(1, 2)\n",
    "        output, hidden = self.gru(dx_proj, hidden)\n",
    "        \n",
    "        gru_features = output[:, -1, :]\n",
    "        combined = torch.cat([dx, gru_features], dim=1)\n",
    "        delta = self.fusion(combined).squeeze(-1)\n",
    "        prediction = x[:, -1] + delta\n",
    "        \n",
    "        return prediction, hidden\n",
    "    \n",
    "    def forward_multistep(self, windows, n_steps):\n",
    "        predictions = []\n",
    "        current_window = windows.clone()\n",
    "        hidden = None\n",
    "        \n",
    "        for _ in range(n_steps):\n",
    "            pred, hidden = self.forward(current_window, hidden)\n",
    "            predictions.append(pred.unsqueeze(1))\n",
    "            current_window = torch.cat([current_window[:, 1:], pred.unsqueeze(1)], dim=1)\n",
    "        \n",
    "        return torch.cat(predictions, dim=1)\n",
    "\n",
    "\n",
    "class LightAttention(ForecastingMixin, nn.Module):\n",
    "    def __init__(self, window_size, embed_dim=64, num_heads=8, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.window_size = window_size\n",
    "        self.dwindow_size = window_size - 1\n",
    "        \n",
    "        self.embed = nn.Conv1d(1, embed_dim, 1, bias=False)\n",
    "        \n",
    "        self.position_enc = nn.Parameter(torch.randn(1, self.dwindow_size, embed_dim))\n",
    "        \n",
    "        self.attention_layers = nn.ModuleList([\n",
    "            nn.MultiheadAttention(\n",
    "                embed_dim, num_heads,\n",
    "                dropout=0.1,\n",
    "                bias=False,\n",
    "                batch_first=True\n",
    "            )\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.layer_norms = nn.ModuleList([\n",
    "            nn.LayerNorm(embed_dim)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(embed_dim + self.dwindow_size, embed_dim, bias=False),\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(embed_dim, embed_dim // 2, bias=False),\n",
    "            nn.LayerNorm(embed_dim // 2),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(embed_dim // 2, 1, bias=False)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Linear, nn.Conv1d)):\n",
    "                nn.init.kaiming_uniform_(m.weight, a=0.01, mode='fan_in')\n",
    "            elif isinstance(m, nn.LayerNorm):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        dx = x[:, 1:] - x[:, :-1]\n",
    "        \n",
    "        dx_reshaped = dx.unsqueeze(1)\n",
    "        dx_embedded = self.embed(dx_reshaped)\n",
    "        dx_embedded = dx_embedded.transpose(1, 2)\n",
    "        dx_embedded = dx_embedded + self.position_enc\n",
    "        \n",
    "        attn_out = dx_embedded\n",
    "        for attn_layer, norm in zip(self.attention_layers, self.layer_norms):\n",
    "            residual = attn_out\n",
    "            attn_out, _ = attn_layer(attn_out, attn_out, attn_out)\n",
    "            attn_out = norm(residual + attn_out)\n",
    "        \n",
    "        attn_features = attn_out[:, -1, :]\n",
    "        \n",
    "        combined = torch.cat([dx, attn_features], dim=1)\n",
    "        delta = self.fusion(combined).squeeze(-1)\n",
    "        \n",
    "        return x[:, -1] + delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e417de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import json\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, time_series: np.ndarray, window_size, n_train_steps=1):\n",
    "        super().__init__()\n",
    "        self.ts = time_series\n",
    "        self.n_train_steps = n_train_steps\n",
    "        self.window_length = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ts) - self.window_length - self.n_train_steps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx_last = idx + self.window_length\n",
    "        return self.ts[idx:idx_last], self.ts[idx_last: idx_last + self.n_train_steps]\n",
    "\n",
    "\n",
    "class MAPELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        mape = torch.abs(predictions - targets) / (torch.abs(targets) + self.eps)\n",
    "        return mape.mean()\n",
    "\n",
    "\n",
    "class WeightedLoss(nn.Module):\n",
    "    def __init__(self, mape=0.1, mse=0.9, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.mape = MAPELoss(eps)\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.mape_weight = mape\n",
    "        self.mse_weight = mse\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        return self.mape_weight * self.mape(predictions, targets) + self.mse_weight * self.mse(predictions, targets)\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, setup, time_series, window_size, len_train, log_path, batch_size=64, \n",
    "                 log_freq_batch=50, n_tests=100, n_test_steps=50, n_train_steps=1, eps=1e-8, device='cuda'):\n",
    "        self.train_series = time_series[:len_train]\n",
    "        self.eval_series = time_series[len_train:]\n",
    "        dataset = TimeSeriesDataset(self.train_series, window_size=window_size, n_train_steps=n_train_steps)\n",
    "        self.dataloader = DataLoader(dataset, batch_size, shuffle=True)\n",
    "\n",
    "        self.window_size = window_size\n",
    "        self.n_epochs = setup['n_epochs']\n",
    "        self.n_tests = n_tests\n",
    "        self.n_test_steps = n_test_steps\n",
    "        self.model = setup['model_class'](**setup['model_args']).to(device)\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), setup['lr'])\n",
    "        self.criterion = WeightedLoss()\n",
    "        self.scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "            self.optimizer, 1.0, 1e-8, self.n_epochs\n",
    "        )\n",
    "\n",
    "        self.loss_threshold = 0.01\n",
    "        self.eps = eps\n",
    "        self.device = device\n",
    "        self.log_freq_batch = log_freq_batch\n",
    "        self.log_path = log_path\n",
    "        \n",
    "        self.n_train_steps = n_train_steps\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate(self):\n",
    "        preds = self.model.generate_forecast(\n",
    "            idx=-1,\n",
    "            time_series=self.train_series,\n",
    "            n_test_steps=self.n_test_steps,\n",
    "            window_size=self.window_size\n",
    "        ).cpu().numpy()\n",
    "        target = self.eval_series[:self.n_test_steps]\n",
    "        return preds, target\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def evaluate_multistep(self, test_ids):\n",
    "        preds = np.empty((self.n_tests + 1, self.n_test_steps))\n",
    "        targets = np.empty((self.n_tests + 1, self.n_test_steps))\n",
    "        for test in range(self.n_tests):\n",
    "            idx = test_ids[test]\n",
    "            target_idx = idx + 1\n",
    "            pred = self.model.generate_forecast(\n",
    "                idx=idx,\n",
    "                time_series=self.train_series,\n",
    "                n_test_steps=self.n_test_steps,\n",
    "                window_size=self.window_size\n",
    "            ).cpu()\n",
    "            target = self.train_series[target_idx:target_idx + self.n_test_steps]\n",
    "            preds[test, :] = pred.numpy()\n",
    "            targets[test, :] = target\n",
    "        return preds, targets\n",
    "\n",
    "    def run(self, test_ids):\n",
    "        epoch_train_time = 0\n",
    "        epoch_val_time = 0\n",
    "        start_full = time()\n",
    "        for epoch in range(1, self.n_epochs + 1):\n",
    "            self.model.train()\n",
    "            start_train = time()\n",
    "            avg_threshold = self.train_epoch(epoch)\n",
    "            epoch_train_time += time() - start_train\n",
    "            self.model.eval()\n",
    "\n",
    "            start_test = time()\n",
    "            preds, targets = self.evaluate_multistep(test_ids)\n",
    "            pred, target = self.validate()\n",
    "            epoch_val_time += time() - start_test\n",
    "            preds[-1, :] = pred\n",
    "            targets[-1, :] = target\n",
    "            tests_results = np.stack([preds, targets], axis=-1)  # shape: [n_tests+1, n_steps, 2]\n",
    "            \n",
    "            np.save(self.log_path / f'epoch_{epoch}', tests_results)\n",
    "            \n",
    "            if avg_threshold < self.loss_threshold:\n",
    "                break\n",
    "        \n",
    "        time_full = time() - start_full\n",
    "        mean_train_time = epoch_train_time / epoch\n",
    "        mean_test_time = epoch_val_time / epoch / (self.n_test_steps + 1) / (self.n_tests)\n",
    "\n",
    "        json.dump(\n",
    "                {\n",
    "                    'full_time': float(time_full),\n",
    "                    'epoch_train_time': float(mean_train_time),\n",
    "                    'epoch_test_time_one_step': float(mean_test_time),\n",
    "                    'last_loss': float(avg_threshold)\n",
    "                },\n",
    "                open(self.log_path / 'times.json', 'w'),\n",
    "                indent=2\n",
    "            )\n",
    "        print()\n",
    "        print(\"Training completed!\")\n",
    "        return self.model\n",
    "    \n",
    "    def train_epoch(self, epoch_idx=0):\n",
    "        print(\"Epoch:\", epoch_idx)\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch_idx, (windows, y) in enumerate(self.dataloader):\n",
    "            windows = windows.to(self.device).float()\n",
    "            y = y.to(self.device).float()\n",
    "            if self.n_train_steps == 1:\n",
    "                y = y.squeeze(-1)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            if self.n_train_steps == 1:\n",
    "                results = self.model.forward(windows)\n",
    "                if isinstance(results, tuple):\n",
    "                    results = results[0]\n",
    "            else:\n",
    "                results = self.model.forward_multistep(windows, self.n_train_steps)\n",
    "\n",
    "            loss = self.criterion(results, y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=0.5)\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if batch_idx % self.log_freq_batch == 0:\n",
    "                basic_metrics = self.compute_basic_metrics(results, y)\n",
    "                print(\"Batch IDX:\", batch_idx)\n",
    "                print(basic_metrics)\n",
    "                print()\n",
    "            if torch.isnan(loss):\n",
    "                print(f\"WARNING: NaN loss at batch {batch_idx}\")\n",
    "                break\n",
    "        self.scheduler.step()\n",
    "\n",
    "        avg_loss = total_loss / len(self.dataloader)\n",
    "        print(f\"Epoch {epoch_idx} - Average Loss: {avg_loss:.6f}\")\n",
    "        return avg_loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def compute_basic_metrics(self, forecast, y_true):\n",
    "        mae = torch.abs(forecast - y_true).mean().item()\n",
    "        mse = torch.mean((forecast - y_true) ** 2).item()\n",
    "        mape = torch.abs((forecast - y_true) / (y_true.abs() + self.eps)).mean().item() * 100\n",
    "        return {'MAE': mae, 'MSE': mse, 'MAPE': mape}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa96e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def get_setups(window_size):\n",
    "    base_configs = []\n",
    "    \n",
    "    # MLP Model\n",
    "    base_configs.append({\n",
    "        'model_class': MLP,\n",
    "        'model_args': {'window_size': window_size, 'hidden_dim': 80},\n",
    "        'name': f'MLP',\n",
    "        'lr': 1e-3,\n",
    "        'n_epochs': 150\n",
    "    })\n",
    "    \n",
    "    # TCN Model\n",
    "    base_configs.append({\n",
    "        'model_class': TCNForecaster,\n",
    "        'model_args': {'window_size': window_size, 'hidden_dim': 64},\n",
    "        'name': f'TCN',\n",
    "        'lr': 1e-3,\n",
    "        'n_epochs': 150\n",
    "    })\n",
    "    \n",
    "    # LightAttention Model\n",
    "    base_configs.append({\n",
    "        'model_class': LightAttention,\n",
    "        'model_args': {'window_size': window_size, 'embed_dim': 64, 'num_heads': 4},\n",
    "        'name': 'LightAttention',\n",
    "        'lr': 1e-3,\n",
    "        'n_epochs': 150,\n",
    "    })\n",
    "    \n",
    "    # LightGRU Model\n",
    "    base_configs.append({\n",
    "        'model_class': LightGRU,\n",
    "        'model_args': {'window_size': window_size, 'hidden_size': 64, 'proj_size': 64},\n",
    "        'name': 'LightGRU',\n",
    "        'lr': 1e-2,\n",
    "        'n_epochs': 300\n",
    "    })\n",
    "    \n",
    "    # EMForecaster Model\n",
    "    em_configs = [\n",
    "        {'n_components': 2, 'dx_linear': False},\n",
    "        {'n_components': 3, 'dx_linear': False},\n",
    "        {'n_components': 2, 'dx_linear': True},\n",
    "        {'n_components': 3, 'dx_linear': True},\n",
    "    ]\n",
    "    \n",
    "    for config in em_configs:\n",
    "        base_configs.append({\n",
    "            'model_class': EMForecaster,\n",
    "            'model_args': {\n",
    "                'window_size': window_size,\n",
    "                'dx_linear': config['dx_linear'],\n",
    "                'n_components': config['n_components'],\n",
    "                'hidden_dim': 64,\n",
    "                'n_em_iters': 5\n",
    "            },\n",
    "            'name': f'EM_n{config[\"n_components\"]}_dx_{config[\"dx_linear\"]}',\n",
    "            'lr': 1e-3,\n",
    "            'n_epochs': 150\n",
    "        })\n",
    "    \n",
    "    return base_configs\n",
    "\n",
    "def create_experiment_folder(base_path=\"experiments\", model_name=None, series_idx=None):\n",
    "    \"\"\"\n",
    "    Create folder structure: experiments/<model_name>/<series_idx>/\n",
    "    \"\"\"\n",
    "    if model_name is None:\n",
    "        model_name = \"default\"\n",
    "    if series_idx is None:\n",
    "        series_idx = \"0\"\n",
    "    \n",
    "    exp_path = Path(base_path) / model_name / str(series_idx)\n",
    "    exp_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    return exp_path\n",
    "\n",
    "def generate_test_ids(window_size, train_series, n_tests, n_test_steps):\n",
    "    res = []\n",
    "    for _ in range(n_tests):\n",
    "        res.append(random.randint(window_size, len(train_series) - 1 - n_test_steps))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3eb8019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Baseline                                 [1]                       --\n",
      "├─Sequential: 1-1                        [1, 1]                    --\n",
      "│    └─Linear: 2-1                       [1, 32]                   3,168\n",
      "│    └─LeakyReLU: 2-2                    [1, 32]                   --\n",
      "│    └─Linear: 2-3                       [1, 1]                    32\n",
      "==========================================================================================\n",
      "Total params: 3,200\n",
      "Trainable params: 3,200\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.01\n",
      "==========================================================================================\n",
      "\n",
      "EM_n2\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "EMForecaster                             [1]                       --\n",
      "├─NormalMixtureEM: 1-1                   [1, 99, 2]                107\n",
      "├─Sequential: 1-2                        [1, 1]                    --\n",
      "│    └─Linear: 2-1                       [1, 32]                   3,680\n",
      "│    └─LeakyReLU: 2-2                    [1, 32]                   --\n",
      "│    └─Linear: 2-3                       [1, 1]                    32\n",
      "==========================================================================================\n",
      "Total params: 3,819\n",
      "Trainable params: 3,815\n",
      "Non-trainable params: 4\n",
      "Total mult-adds (M): 0.01\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.02\n",
      "==========================================================================================\n",
      "\n",
      "EM_n3\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "EMForecaster                             [1]                       --\n",
      "├─NormalMixtureEM: 1-1                   [1, 99, 3]                110\n",
      "├─Sequential: 1-2                        [1, 1]                    --\n",
      "│    └─Linear: 2-1                       [1, 32]                   3,936\n",
      "│    └─LeakyReLU: 2-2                    [1, 32]                   --\n",
      "│    └─Linear: 2-3                       [1, 1]                    32\n",
      "==========================================================================================\n",
      "Total params: 4,078\n",
      "Trainable params: 4,072\n",
      "Non-trainable params: 6\n",
      "Total mult-adds (M): 0.01\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.02\n",
      "==========================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "window_size = 100\n",
    "\n",
    "for setup in get_setups(window_size):\n",
    "    model = setup['model_class'](**setup['model_args'])\n",
    "    print(setup['name'])\n",
    "    print(summary(model, input_data=torch.ones((1, window_size))))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e34ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "0\n",
      "__________________________________________________\n",
      "N = 5; Max ACF(1): 0.9999998807907104\n",
      "N = 10; Max ACF(1): 0.971988320350647\n",
      "N = 15; Max ACF(1): 0.896878719329834\n",
      "N = 20; Max ACF(1): 0.861565351486206\n",
      "N = 25; Max ACF(1): 0.8270503878593445\n",
      "N = 30; Max ACF(1): 0.8007834553718567\n",
      "N = 35; Max ACF(1): 0.793499767780304\n",
      "N = 40; Max ACF(1): 0.7914840579032898\n",
      "N = 45; Max ACF(1): 0.789178729057312\n",
      "N = 50; Max ACF(1): 0.7675512433052063\n",
      "N = 55; Max ACF(1): 0.7647435069084167\n",
      "N = 60; Max ACF(1): 0.7662709355354309\n",
      "N = 65; Max ACF(1): 0.7611182332038879\n",
      "N = 70; Max ACF(1): 0.7609160542488098\n",
      "N = 75; Max ACF(1): 0.7589223384857178\n",
      "N = 80; Max ACF(1): 0.7473089098930359\n",
      "N = 85; Max ACF(1): 0.7415372729301453\n",
      "N = 90; Max ACF(1): 0.7400791049003601\n",
      "N = 95; Max ACF(1): 0.7308598160743713\n",
      "N = 100; Max ACF(1): 0.7267736196517944\n",
      "N = 105; Max ACF(1): 0.7119746804237366\n",
      "Found window length: 105\n",
      "__________________________________________________\n",
      "Baseline\n",
      "__________________________________________________\n",
      "Epoch: 1\n",
      "Batch IDX: 0\n",
      "{'MAE': 1.791450023651123, 'MSE': 4.900669097900391, 'MAPE': 4.151567444205284}\n",
      "\n",
      "Epoch 1 - Average Loss: 3.262974\n",
      "Epoch: 2\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.9399117827415466, 'MSE': 1.5239663124084473, 'MAPE': 5.637160316109657}\n",
      "\n",
      "Epoch 2 - Average Loss: 2.093978\n",
      "Epoch: 3\n",
      "Batch IDX: 0\n",
      "{'MAE': 1.051966905593872, 'MSE': 1.6573054790496826, 'MAPE': 3.4222006797790527}\n",
      "\n",
      "Epoch 3 - Average Loss: 1.886351\n",
      "Epoch: 4\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.8428257703781128, 'MSE': 1.154625415802002, 'MAPE': 5.421401560306549}\n",
      "\n",
      "Epoch 4 - Average Loss: 1.770566\n",
      "Epoch: 5\n",
      "Batch IDX: 0\n",
      "{'MAE': 1.1240278482437134, 'MSE': 2.3991410732269287, 'MAPE': 3.4885693341493607}\n",
      "\n",
      "Epoch 5 - Average Loss: 1.623763\n",
      "Epoch: 6\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.7861862182617188, 'MSE': 0.9817078113555908, 'MAPE': 2.9737360775470734}\n",
      "\n",
      "Epoch 6 - Average Loss: 1.536235\n",
      "Epoch: 7\n",
      "Batch IDX: 0\n",
      "{'MAE': 1.1033834218978882, 'MSE': 1.848925232887268, 'MAPE': 3.5867907106876373}\n",
      "\n",
      "Epoch 7 - Average Loss: 1.453715\n",
      "Epoch: 8\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.8725115060806274, 'MSE': 1.147068738937378, 'MAPE': 3.513648360967636}\n",
      "\n",
      "Epoch 8 - Average Loss: 1.373230\n",
      "Epoch: 9\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.9154561758041382, 'MSE': 1.3082096576690674, 'MAPE': 2.144174464046955}\n",
      "\n",
      "Epoch 9 - Average Loss: 1.317545\n",
      "Epoch: 10\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.8702279329299927, 'MSE': 1.2641280889511108, 'MAPE': 1.7411492764949799}\n",
      "\n",
      "Epoch 10 - Average Loss: 1.241686\n",
      "Epoch: 11\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.8316787481307983, 'MSE': 1.0171682834625244, 'MAPE': 1.6210101544857025}\n",
      "\n",
      "Epoch 11 - Average Loss: 1.174043\n",
      "Epoch: 12\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.7532386183738708, 'MSE': 1.0323632955551147, 'MAPE': 2.063891291618347}\n",
      "\n",
      "Epoch 12 - Average Loss: 1.114138\n",
      "Epoch: 13\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.7728716731071472, 'MSE': 0.9374154806137085, 'MAPE': 9.23352763056755}\n",
      "\n",
      "Epoch 13 - Average Loss: 1.053660\n",
      "Epoch: 14\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.747788667678833, 'MSE': 0.888351559638977, 'MAPE': 1.7887992784380913}\n",
      "\n",
      "Epoch 14 - Average Loss: 1.017759\n",
      "Epoch: 15\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.7610013484954834, 'MSE': 0.9019392728805542, 'MAPE': 1.715320348739624}\n",
      "\n",
      "Epoch 15 - Average Loss: 0.950361\n",
      "Epoch: 16\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.7249289751052856, 'MSE': 0.8312735557556152, 'MAPE': 4.3854620307683945}\n",
      "\n",
      "Epoch 16 - Average Loss: 0.895092\n",
      "Epoch: 17\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.8069086074829102, 'MSE': 1.0918536186218262, 'MAPE': 3.5603612661361694}\n",
      "\n",
      "Epoch 17 - Average Loss: 0.844162\n",
      "Epoch: 18\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.6823641061782837, 'MSE': 0.7204897403717041, 'MAPE': 2.0529069006443024}\n",
      "\n",
      "Epoch 18 - Average Loss: 0.821003\n",
      "Epoch: 19\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.7569447755813599, 'MSE': 0.8831944465637207, 'MAPE': 4.443888738751411}\n",
      "\n",
      "Epoch 19 - Average Loss: 0.785322\n",
      "Epoch: 20\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.5961892604827881, 'MSE': 0.6236405372619629, 'MAPE': 9.251654148101807}\n",
      "\n",
      "Epoch 20 - Average Loss: 0.751648\n",
      "Epoch: 21\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.604424238204956, 'MSE': 0.617084264755249, 'MAPE': 1.2330643832683563}\n",
      "\n",
      "Epoch 21 - Average Loss: 0.705662\n",
      "Epoch: 22\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.576316773891449, 'MSE': 0.5820274353027344, 'MAPE': 1.0339156724512577}\n",
      "\n",
      "Epoch 22 - Average Loss: 0.685332\n",
      "Epoch: 23\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.6036573052406311, 'MSE': 0.7172414064407349, 'MAPE': 1.4504706487059593}\n",
      "\n",
      "Epoch 23 - Average Loss: 0.661716\n",
      "Epoch: 24\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.6977661848068237, 'MSE': 0.7379226684570312, 'MAPE': 1.7283547669649124}\n",
      "\n",
      "Epoch 24 - Average Loss: 0.631526\n",
      "Epoch: 25\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.5923237204551697, 'MSE': 0.5039830207824707, 'MAPE': 1.7799511551856995}\n",
      "\n",
      "Epoch 25 - Average Loss: 0.606994\n",
      "Epoch: 26\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.5382494926452637, 'MSE': 0.5402169823646545, 'MAPE': 1.1707045137882233}\n",
      "\n",
      "Epoch 26 - Average Loss: 0.593833\n",
      "Epoch: 27\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.491828978061676, 'MSE': 0.40992143750190735, 'MAPE': 1.160393375903368}\n",
      "\n",
      "Epoch 27 - Average Loss: 0.567631\n",
      "Epoch: 28\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.590438961982727, 'MSE': 0.5395808219909668, 'MAPE': 0.8855769410729408}\n",
      "\n",
      "Epoch 28 - Average Loss: 0.554291\n",
      "Epoch: 29\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.46054840087890625, 'MSE': 0.3519958257675171, 'MAPE': 1.0773345828056335}\n",
      "\n",
      "Epoch 29 - Average Loss: 0.525732\n",
      "Epoch: 30\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.46491745114326477, 'MSE': 0.3411210775375366, 'MAPE': 0.7540633901953697}\n",
      "\n",
      "Epoch 30 - Average Loss: 0.516908\n",
      "Epoch: 31\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.5403360724449158, 'MSE': 0.45684683322906494, 'MAPE': 1.9196923822164536}\n",
      "\n",
      "Epoch 31 - Average Loss: 0.506173\n",
      "Epoch: 32\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.5061447024345398, 'MSE': 0.40724480152130127, 'MAPE': 0.870048999786377}\n",
      "\n",
      "Epoch 32 - Average Loss: 0.474961\n",
      "Epoch: 33\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.48266327381134033, 'MSE': 0.36361223459243774, 'MAPE': 1.8829196691513062}\n",
      "\n",
      "Epoch 33 - Average Loss: 0.471317\n",
      "Epoch: 34\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.36767542362213135, 'MSE': 0.2277671992778778, 'MAPE': 1.4056704938411713}\n",
      "\n",
      "Epoch 34 - Average Loss: 0.449715\n",
      "Epoch: 35\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.4371407628059387, 'MSE': 0.3049052953720093, 'MAPE': 0.851801224052906}\n",
      "\n",
      "Epoch 35 - Average Loss: 0.442276\n",
      "Epoch: 36\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.43561315536499023, 'MSE': 0.2890501022338867, 'MAPE': 12.91636973619461}\n",
      "\n",
      "Epoch 36 - Average Loss: 0.428935\n",
      "Epoch: 37\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.43950822949409485, 'MSE': 0.3175205588340759, 'MAPE': 1.3065418228507042}\n",
      "\n",
      "Epoch 37 - Average Loss: 0.416895\n",
      "Epoch: 38\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.38864630460739136, 'MSE': 0.2901260256767273, 'MAPE': 0.9362476877868176}\n",
      "\n",
      "Epoch 38 - Average Loss: 0.404960\n",
      "Epoch: 39\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.46091508865356445, 'MSE': 0.33774882555007935, 'MAPE': 0.8227260783314705}\n",
      "\n",
      "Epoch 39 - Average Loss: 0.400928\n",
      "Epoch: 40\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.4879242777824402, 'MSE': 0.44301122426986694, 'MAPE': 1.2926583178341389}\n",
      "\n",
      "Epoch 40 - Average Loss: 0.386127\n",
      "Epoch: 41\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.4977806806564331, 'MSE': 0.39446061849594116, 'MAPE': 1.6913965344429016}\n",
      "\n",
      "Epoch 41 - Average Loss: 0.372531\n",
      "Epoch: 42\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.44093772768974304, 'MSE': 0.3293161392211914, 'MAPE': 1.695837639272213}\n",
      "\n",
      "Epoch 42 - Average Loss: 0.363221\n",
      "Epoch: 43\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.4099230468273163, 'MSE': 0.319945365190506, 'MAPE': 0.7245682179927826}\n",
      "\n",
      "Epoch 43 - Average Loss: 0.359962\n",
      "Epoch: 44\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.4500408470630646, 'MSE': 0.3842661380767822, 'MAPE': 3.6372803151607513}\n",
      "\n",
      "Epoch 44 - Average Loss: 0.348666\n",
      "Epoch: 45\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.4298880398273468, 'MSE': 0.4001077115535736, 'MAPE': 0.8899825625121593}\n",
      "\n",
      "Epoch 45 - Average Loss: 0.342485\n",
      "Epoch: 46\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.4352445900440216, 'MSE': 0.295149564743042, 'MAPE': 0.8083771914243698}\n",
      "\n",
      "Epoch 46 - Average Loss: 0.333318\n",
      "Epoch: 47\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.3769237995147705, 'MSE': 0.2335146814584732, 'MAPE': 3.204549103975296}\n",
      "\n",
      "Epoch 47 - Average Loss: 0.332369\n",
      "Epoch: 48\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.36978867650032043, 'MSE': 0.25100916624069214, 'MAPE': 0.7910944521427155}\n",
      "\n",
      "Epoch 48 - Average Loss: 0.321501\n",
      "Epoch: 49\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.3766542673110962, 'MSE': 0.24631226062774658, 'MAPE': 1.4200763776898384}\n",
      "\n",
      "Epoch 49 - Average Loss: 0.313250\n",
      "Epoch: 50\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.46261265873908997, 'MSE': 0.37262535095214844, 'MAPE': 1.4284171164035797}\n",
      "\n",
      "Epoch 50 - Average Loss: 0.307353\n",
      "Epoch: 51\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.36806923151016235, 'MSE': 0.21854712069034576, 'MAPE': 0.8324653841555119}\n",
      "\n",
      "Epoch 51 - Average Loss: 0.301747\n",
      "Epoch: 52\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.3556630611419678, 'MSE': 0.2111123651266098, 'MAPE': 0.8899613283574581}\n",
      "\n",
      "Epoch 52 - Average Loss: 0.297580\n",
      "Epoch: 53\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.4139629900455475, 'MSE': 0.2835322320461273, 'MAPE': 0.9650852531194687}\n",
      "\n",
      "Epoch 53 - Average Loss: 0.294287\n",
      "Epoch: 54\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.429191917181015, 'MSE': 0.3058377504348755, 'MAPE': 0.7898168638348579}\n",
      "\n",
      "Epoch 54 - Average Loss: 0.284541\n",
      "Epoch: 55\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.334597110748291, 'MSE': 0.2227754443883896, 'MAPE': 3.647829592227936}\n",
      "\n",
      "Epoch 55 - Average Loss: 0.278899\n",
      "Epoch: 56\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.32009226083755493, 'MSE': 0.17366881668567657, 'MAPE': 4.82475608587265}\n",
      "\n",
      "Epoch 56 - Average Loss: 0.276791\n",
      "Epoch: 57\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.3694409132003784, 'MSE': 0.2076728790998459, 'MAPE': 1.2900731526315212}\n",
      "\n",
      "Epoch 57 - Average Loss: 0.273849\n",
      "Epoch: 58\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.3554421365261078, 'MSE': 0.22155475616455078, 'MAPE': 0.8652806282043457}\n",
      "\n",
      "Epoch 58 - Average Loss: 0.266203\n",
      "Epoch: 59\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.3490166962146759, 'MSE': 0.1954561471939087, 'MAPE': 0.8318664506077766}\n",
      "\n",
      "Epoch 59 - Average Loss: 0.261995\n",
      "Epoch: 60\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.42056137323379517, 'MSE': 0.2591758370399475, 'MAPE': 2.551143430173397}\n",
      "\n",
      "Epoch 60 - Average Loss: 0.267302\n",
      "Epoch: 61\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.39822709560394287, 'MSE': 0.33191293478012085, 'MAPE': 1.0172155685722828}\n",
      "\n",
      "Epoch 61 - Average Loss: 0.252312\n",
      "Epoch: 62\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.41803276538848877, 'MSE': 0.2818458080291748, 'MAPE': 5.301831662654877}\n",
      "\n",
      "Epoch 62 - Average Loss: 0.250428\n",
      "Epoch: 63\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.3908025026321411, 'MSE': 0.29035434126853943, 'MAPE': 0.712462654337287}\n",
      "\n",
      "Epoch 63 - Average Loss: 0.248598\n",
      "Epoch: 64\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.4002603590488434, 'MSE': 0.26234814524650574, 'MAPE': 1.045810803771019}\n",
      "\n",
      "Epoch 64 - Average Loss: 0.248000\n",
      "Epoch: 65\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.3889999985694885, 'MSE': 0.2295762151479721, 'MAPE': 0.8599448949098587}\n",
      "\n",
      "Epoch 65 - Average Loss: 0.243856\n",
      "Epoch: 66\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.3604835271835327, 'MSE': 0.22382107377052307, 'MAPE': 0.9458581916987896}\n",
      "\n",
      "Epoch 66 - Average Loss: 0.238741\n",
      "Epoch: 67\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.34626227617263794, 'MSE': 0.20059028267860413, 'MAPE': 0.7629913277924061}\n",
      "\n",
      "Epoch 67 - Average Loss: 0.242041\n",
      "Epoch: 68\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.38831645250320435, 'MSE': 0.28055042028427124, 'MAPE': 1.408022828400135}\n",
      "\n",
      "Epoch 68 - Average Loss: 0.233008\n",
      "Epoch: 69\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.3656679391860962, 'MSE': 0.20829017460346222, 'MAPE': 3.3798035234212875}\n",
      "\n",
      "Epoch 69 - Average Loss: 0.230251\n",
      "Epoch: 70\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.29228103160858154, 'MSE': 0.1642639935016632, 'MAPE': 2.4106571450829506}\n",
      "\n",
      "Epoch 70 - Average Loss: 0.226832\n",
      "Epoch: 71\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.40720558166503906, 'MSE': 0.2607787847518921, 'MAPE': 0.7889304310083389}\n",
      "\n",
      "Epoch 71 - Average Loss: 0.225519\n",
      "Epoch: 72\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.36194291710853577, 'MSE': 0.23051124811172485, 'MAPE': 0.6838327273726463}\n",
      "\n",
      "Epoch 72 - Average Loss: 0.223573\n",
      "Epoch: 73\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.3256874084472656, 'MSE': 0.17130553722381592, 'MAPE': 0.7084955461323261}\n",
      "\n",
      "Epoch 73 - Average Loss: 0.218818\n",
      "Epoch: 74\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.338220477104187, 'MSE': 0.20879000425338745, 'MAPE': 3.626423329114914}\n",
      "\n",
      "Epoch 74 - Average Loss: 0.221128\n",
      "Epoch: 75\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.39032864570617676, 'MSE': 0.31299299001693726, 'MAPE': 3.898325562477112}\n",
      "\n",
      "Epoch 75 - Average Loss: 0.219891\n",
      "Epoch: 76\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.3713119924068451, 'MSE': 0.20110613107681274, 'MAPE': 0.678195571526885}\n",
      "\n",
      "Epoch 76 - Average Loss: 0.214429\n",
      "Epoch: 77\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.3994865119457245, 'MSE': 0.24680259823799133, 'MAPE': 0.8829990401864052}\n",
      "\n",
      "Epoch 77 - Average Loss: 0.215364\n",
      "Epoch: 78\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.31717929244041443, 'MSE': 0.15043944120407104, 'MAPE': 0.6085505243390799}\n",
      "\n",
      "Epoch 78 - Average Loss: 0.210768\n",
      "Epoch: 79\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.3437439203262329, 'MSE': 0.2003895342350006, 'MAPE': 1.1965392157435417}\n",
      "\n",
      "Epoch 79 - Average Loss: 0.211932\n",
      "Epoch: 80\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.3147376775741577, 'MSE': 0.1761561930179596, 'MAPE': 0.6119589786976576}\n",
      "\n",
      "Epoch 80 - Average Loss: 0.208523\n",
      "\n",
      "Training completed!\n",
      "__________________________________________________\n",
      "EM_n2\n",
      "__________________________________________________\n",
      "Epoch: 1\n",
      "Batch IDX: 0\n",
      "{'MAE': 1.6754248142242432, 'MSE': 6.730767250061035, 'MAPE': 4.33364138007164}\n",
      "\n",
      "Epoch 1 - Average Loss: 3.068955\n",
      "Epoch: 2\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.9999327063560486, 'MSE': 1.482736349105835, 'MAPE': 3.427990898489952}\n",
      "\n",
      "Epoch 2 - Average Loss: 2.069263\n",
      "Epoch: 3\n",
      "Batch IDX: 0\n",
      "{'MAE': 1.0445821285247803, 'MSE': 1.926516056060791, 'MAPE': 2.2151578217744827}\n",
      "\n",
      "Epoch 3 - Average Loss: 1.855224\n",
      "Epoch: 4\n",
      "Batch IDX: 0\n",
      "{'MAE': 1.0096840858459473, 'MSE': 1.5290002822875977, 'MAPE': 2.820335701107979}\n",
      "\n",
      "Epoch 4 - Average Loss: 1.706914\n",
      "Epoch: 5\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.9049760103225708, 'MSE': 1.3447763919830322, 'MAPE': 2.9756249859929085}\n",
      "\n",
      "Epoch 5 - Average Loss: 1.607799\n",
      "Epoch: 6\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.9195232391357422, 'MSE': 1.52347731590271, 'MAPE': 8.745288848876953}\n",
      "\n",
      "Epoch 6 - Average Loss: 1.490696\n",
      "Epoch: 7\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.8940039873123169, 'MSE': 1.5201653242111206, 'MAPE': 22.131146490573883}\n",
      "\n",
      "Epoch 7 - Average Loss: 1.438056\n",
      "Epoch: 8\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.8916055560112, 'MSE': 1.3909094333648682, 'MAPE': 3.133213520050049}\n",
      "\n",
      "Epoch 8 - Average Loss: 1.328238\n",
      "Epoch: 9\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.9080812931060791, 'MSE': 1.31919527053833, 'MAPE': 4.605827480554581}\n",
      "\n",
      "Epoch 9 - Average Loss: 1.255984\n",
      "Epoch: 10\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.8469099402427673, 'MSE': 1.1164071559906006, 'MAPE': 1.6690317541360855}\n",
      "\n",
      "Epoch 10 - Average Loss: 1.208652\n",
      "Epoch: 11\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.9340676665306091, 'MSE': 1.41077721118927, 'MAPE': 2.512330934405327}\n",
      "\n",
      "Epoch 11 - Average Loss: 1.108177\n",
      "Epoch: 12\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.7437924742698669, 'MSE': 1.0166466236114502, 'MAPE': 2.7901723980903625}\n",
      "\n",
      "Epoch 12 - Average Loss: 1.062972\n",
      "Epoch: 13\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.616426944732666, 'MSE': 0.6985986232757568, 'MAPE': 3.5263150930404663}\n",
      "\n",
      "Epoch 13 - Average Loss: 0.988007\n",
      "Epoch: 14\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.6483542919158936, 'MSE': 0.6898250579833984, 'MAPE': 1.2808553874492645}\n",
      "\n",
      "Epoch 14 - Average Loss: 0.942536\n",
      "Epoch: 15\n",
      "Batch IDX: 0\n",
      "{'MAE': 0.6513898372650146, 'MSE': 0.7022070288658142, 'MAPE': 1.4299443922936916}\n",
      "\n",
      "Epoch 15 - Average Loss: 0.890035\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     31\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(setup, series, window_size, train_length, log_path,\n\u001b[1;32m     32\u001b[0m                   batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, log_freq_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m70\u001b[39m, n_tests\u001b[38;5;241m=\u001b[39mn_epoch_tests, n_test_steps\u001b[38;5;241m=\u001b[39mn_test_steps, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_ids\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 109\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self, test_ids)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    108\u001b[0m start_test \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m--> 109\u001b[0m preds, targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_multistep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m pred, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate()\n\u001b[1;32m    111\u001b[0m epoch_val_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m start_test\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 86\u001b[0m, in \u001b[0;36mTrainer.evaluate_multistep\u001b[0;34m(self, test_ids)\u001b[0m\n\u001b[1;32m     84\u001b[0m idx \u001b[38;5;241m=\u001b[39m test_ids[test]\n\u001b[1;32m     85\u001b[0m target_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 86\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_forecast\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_series\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_series\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_test_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_test_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow_size\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     92\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_series[target_idx:target_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_test_steps]\n\u001b[1;32m     93\u001b[0m preds[test, :] \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 77\u001b[0m, in \u001b[0;36mForecastingMixin.generate_forecast\u001b[0;34m(self, idx, time_series, n_test_steps, window_size)\u001b[0m\n\u001b[1;32m     74\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m     75\u001b[0m window \u001b[38;5;241m=\u001b[39m ts\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 77\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_multistep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_test_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ts\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     79\u001b[0m     preds \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 95\u001b[0m, in \u001b[0;36mForecastingMixin.forward_multistep\u001b[0;34m(self, windows, n_steps)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_multistep\u001b[39m(\u001b[38;5;28mself\u001b[39m, windows: torch\u001b[38;5;241m.\u001b[39mTensor, n_steps: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     84\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    Default multi-step forecasting implementation.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    Can be overridden by subclasses for stateful models.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m        predictions: [batch_size, n_steps]\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless_forward_multistep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 33\u001b[0m, in \u001b[0;36mForecastingMixin.stateless_forward_multistep\u001b[0;34m(self, windows, n_steps)\u001b[0m\n\u001b[1;32m     31\u001b[0m forecasts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_steps):\n\u001b[0;32m---> 33\u001b[0m     forecast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     forecasts\u001b[38;5;241m.\u001b[39mappend(forecast)\n\u001b[1;32m     36\u001b[0m     windows \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[1;32m     37\u001b[0m         windows[:, \u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m     38\u001b[0m         forecast\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     39\u001b[0m     ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 131\u001b[0m, in \u001b[0;36mEMForecaster.forward\u001b[0;34m(self, X_window)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_window):\n\u001b[1;32m    130\u001b[0m     dX \u001b[38;5;241m=\u001b[39m X_window[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m-\u001b[39m X_window[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 131\u001b[0m     g_ik, p_k, a_k, b_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mem_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     attn_1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(b_k, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    133\u001b[0m     attn_2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (b_k \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mem_layer\u001b[38;5;241m.\u001b[39meps), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Statistics/research/sem_lib/sem/sem/EM.py:87\u001b[0m, in \u001b[0;36mNormalMixtureEM.forward\u001b[0;34m(self, windows)\u001b[0m\n\u001b[1;32m     85\u001b[0m p, a, b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_parameters(windows)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_sem_iters):\n\u001b[0;32m---> 87\u001b[0m     g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     p, a, b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_m_step(windows, g)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m g, p, a, b\n",
      "File \u001b[0;32m~/Statistics/research/sem_lib/sem/sem/EM.py:49\u001b[0m, in \u001b[0;36mNormalMixtureEM._e_step\u001b[0;34m(self, windows, p, a, b)\u001b[0m\n\u001b[1;32m     46\u001b[0m log_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog((p \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps) \u001b[38;5;241m/\u001b[39m (b \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     47\u001b[0m log_mixture \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m ((windows\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m a\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m/\u001b[39m\n\u001b[1;32m     48\u001b[0m                     (b\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps)) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m log_weights\n\u001b[0;32m---> 49\u001b[0m log_normalization \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogsumexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_mixture\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m log_responsibilities \u001b[38;5;241m=\u001b[39m log_mixture \u001b[38;5;241m-\u001b[39m log_normalization\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mexp(log_responsibilities)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_tests = 10\n",
    "series_length = 5000\n",
    "train_length = 4500\n",
    "alpha = 0.75\n",
    "N_init = 5\n",
    "N_add = 5\n",
    "n_epoch_tests = 40\n",
    "n_test_steps = 200\n",
    "\n",
    "for test in range(n_tests):\n",
    "    print('_' * 50)\n",
    "    print(test)\n",
    "    print('_' * 50)\n",
    "    set_seed(10 * test)\n",
    "    series = create_sde_process(series_length)['X']\n",
    "    train_series = series[:train_length]\n",
    "    *_, window_size = Windows()(train_series[1:] - train_series[:-1], alpha, N_init, N_add)\n",
    "    window_size += 1\n",
    "    setups = get_setups(window_size)\n",
    "    test_ids = generate_test_ids(window_size, train_series, n_epoch_tests, n_test_steps)\n",
    "    for setup in setups:\n",
    "        set_seed(10 * test)\n",
    "        print('_' * 50)\n",
    "        print(setup['name'])\n",
    "        print('_' * 50)\n",
    "\n",
    "        log_path = create_experiment_folder(model_name=setup['name'], series_idx=test)\n",
    "        if len(os.listdir(log_path)):\n",
    "            print(log_path)\n",
    "            continue\n",
    "        trainer = Trainer(setup, series, window_size, train_length, log_path,\n",
    "                          batch_size=64, log_freq_batch=70, n_tests=n_epoch_tests, n_test_steps=n_test_steps, device='cuda')\n",
    "        model = trainer.run(test_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
