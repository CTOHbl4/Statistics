{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "608242fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def analyze_experiments(experiments_path: str = \"experiments\", skip_models: list = ['LightGRU']) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze all experiments and create comprehensive pandas table.\n",
    "    \n",
    "    Args:\n",
    "        experiments_path: Path to experiments directory\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with metrics for all experiments\n",
    "    \"\"\"\n",
    "    experiments_path = Path(experiments_path)\n",
    "    \n",
    "    # Collect data from all experiments\n",
    "    all_data = []\n",
    "    \n",
    "    for model_dir in experiments_path.iterdir():\n",
    "        if not model_dir.is_dir() or model_dir.name.startswith('.'):\n",
    "            continue\n",
    "            \n",
    "        model_name = model_dir.name\n",
    "        if model_name in skip_models:\n",
    "            continue\n",
    "        \n",
    "        for test_dir in model_dir.iterdir():\n",
    "            if not test_dir.is_dir() or test_dir.name.startswith('.'):\n",
    "                continue\n",
    "                \n",
    "            test_idx = int(test_dir.name)\n",
    "            \n",
    "            try:\n",
    "                # Load time metrics\n",
    "                time_file = test_dir / 'times.json'\n",
    "                if time_file.exists():\n",
    "                    with open(time_file, 'r') as f:\n",
    "                        time_data = json.load(f)\n",
    "                else:\n",
    "                    time_data = {}\n",
    "                \n",
    "                # Find epoch files and calculate training metrics\n",
    "                epoch_files = sorted([f for f in test_dir.iterdir() \n",
    "                                    if f.name.startswith('epoch_') and f.suffix == '.npy'])\n",
    "                \n",
    "                if epoch_files:\n",
    "                    # Calculate convergence speed\n",
    "                    n_epochs = len(epoch_files)\n",
    "                    first_epoch_data = np.load(epoch_files[0])\n",
    "                    test_target = first_epoch_data[-1, :, 1].flatten()\n",
    "\n",
    "                    min_metrics = 1000\n",
    "                    res_file = ''\n",
    "                    for i, epoch_file in enumerate(epoch_files):\n",
    "                        # Calculate metrics\n",
    "                        last_epoch_data = np.load(epoch_file)\n",
    "                        train_pred_last = last_epoch_data[:-1, :, 0]\n",
    "                        train_target_last = last_epoch_data[:-1, :, 1]\n",
    "                        test_pred_last = last_epoch_data[-1, :, 0].flatten()\n",
    "\n",
    "                        test = 0\n",
    "                        test += calculate_mape(train_pred_last, train_target_last)\n",
    "                        # test += calculate_mae(test_pred_last, test_target)\n",
    "                        test += calculate_mape(test_pred_last, test_target)\n",
    "                        if test < min_metrics:\n",
    "                            min_metrics = test\n",
    "                            res_file = epoch_file\n",
    "                            n_epochs = i + 1\n",
    "                    \n",
    "                    best_epoch_data = np.load(res_file)\n",
    "                    train_metrics = calculate_epoch_metrics(first_epoch_data, best_epoch_data)\n",
    "                    # Calculate time efficiency\n",
    "                    time_metrics = calculate_time_metrics(time_data, n_epochs)\n",
    "                    \n",
    "                    # Combine all data\n",
    "                    experiment_data = {\n",
    "                        'model': model_name,\n",
    "                        'test_idx': test_idx,\n",
    "                        'n_epochs': n_epochs,\n",
    "                        **train_metrics,\n",
    "                        **time_metrics,\n",
    "                        **time_data  # Add raw time data\n",
    "                    }\n",
    "                    \n",
    "                    all_data.append(experiment_data)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {model_dir.name}/{test_dir.name}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    # Calculate derived metrics if DataFrame is not empty\n",
    "    if not df.empty:\n",
    "        df = calculate_derived_metrics(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_epoch_metrics(first_epoch_data: np.ndarray, last_epoch_data: np.ndarray) -> Dict:\n",
    "    \"\"\"\n",
    "    Calculate training metrics from first and last epoch.\n",
    "    \"\"\"\n",
    "    # Extract predictions and targets\n",
    "    # Shape: [n_tests+1, n_steps, 2] where last dim: 0=predictions, 1=targets\n",
    "    \n",
    "    train_pred_first = first_epoch_data[:-1, :, 0]\n",
    "    train_target_first = first_epoch_data[:-1, :, 1]\n",
    "    \n",
    "    train_pred_last = last_epoch_data[:-1, :, 0]\n",
    "    train_target_last = last_epoch_data[:-1, :, 1]\n",
    "\n",
    "    test_pred_first = first_epoch_data[-1, :, 0].flatten()\n",
    "    test_target = first_epoch_data[-1, :, 1].flatten()\n",
    "    \n",
    "    test_pred_last = last_epoch_data[-1, :, 0].flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        # Training (validation) metrics - improvement from first to last\n",
    "        'train_mse_first': calculate_mse(train_pred_first, train_target_first),\n",
    "        'train_mse_best': calculate_mse(train_pred_last, train_target_last),\n",
    "        'train_mae_first': calculate_mae(train_pred_first, train_target_first),\n",
    "        'train_mae_best': calculate_mae(train_pred_last, train_target_last),\n",
    "        'train_mape_first': calculate_mape(train_pred_first, train_target_first),\n",
    "        'train_mape_best': calculate_mape(train_pred_last, train_target_last),\n",
    "        \n",
    "        # Testing metrics\n",
    "        'test_mse_first': calculate_mse(test_pred_first, test_target),\n",
    "        'test_mse_best': calculate_mse(test_pred_last, test_target),\n",
    "        'test_mae_first': calculate_mae(test_pred_first, test_target),\n",
    "        'test_mae_best': calculate_mae(test_pred_last, test_target),\n",
    "        'test_mape_first': calculate_mape(test_pred_first, test_target),\n",
    "        'test_mape_best': calculate_mape(test_pred_last, test_target),\n",
    "        \n",
    "        # Improvement ratios\n",
    "        'train_mse_improvement': calculate_improvement(train_pred_first, train_pred_last, train_target_first, train_target_last),\n",
    "        'test_mse_improvement': calculate_improvement(test_pred_first, test_pred_last, test_target, None),\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def calculate_time_metrics(time_data: Dict, n_epochs: int) -> Dict:\n",
    "    \"\"\"\n",
    "    Calculate time-related metrics.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    if time_data:\n",
    "        total_time = time_data.get('full_time', 0)\n",
    "        epoch_train_time = time_data.get('epoch_train_time', 0)\n",
    "        one_step_time = time_data.get('epoch_test_time_one_step', 0)\n",
    "        epoch_total_time = total_time / n_epochs\n",
    "        \n",
    "        metrics.update({\n",
    "            'total_time_minutes': total_time / 60,\n",
    "            'epoch_train_time': epoch_train_time,\n",
    "            'one_step_time': one_step_time,\n",
    "            'epoch_total_time': epoch_total_time,\n",
    "            'speed_epochs_per_minute': 60 / epoch_total_time if epoch_total_time > 0 else 0,\n",
    "        })\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def calculate_derived_metrics(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate additional derived metrics.\n",
    "    \"\"\"\n",
    "    # Improvement percentages\n",
    "    df['train_mse_improvement_pct'] = (1 - df['train_mse_best'] / df['train_mse_first']) * 100\n",
    "    df['test_mse_improvement_pct'] = (1 - df['test_mse_best'] / df['test_mse_first']) * 100\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_mse(predictions: np.ndarray, targets: np.ndarray) -> float:\n",
    "    \"\"\"Calculate Mean Squared Error.\"\"\"\n",
    "    return float(np.mean((predictions - targets) ** 2))\n",
    "\n",
    "\n",
    "def calculate_mae(predictions: np.ndarray, targets: np.ndarray) -> float:\n",
    "    \"\"\"Calculate Mean Absolute Error.\"\"\"\n",
    "    return float(np.mean(np.abs(predictions - targets)))\n",
    "\n",
    "\n",
    "def calculate_mape(predictions: np.ndarray, targets: np.ndarray, eps: float = 1e-8) -> float:\n",
    "    \"\"\"Calculate Mean Absolute Percentage Error.\"\"\"\n",
    "    return float(np.mean(np.abs((predictions - targets) / (np.abs(targets) + eps))) * 100)\n",
    "\n",
    "\n",
    "def calculate_improvement(pred_first: np.ndarray, pred_last: np.ndarray, target_first: np.ndarray, target_last: np.ndarray = None) -> float:\n",
    "    \"\"\"Calculate MSE improvement from first to last epoch.\"\"\"\n",
    "    mse_first = calculate_mse(pred_first, target_first)\n",
    "    if target_last is None:\n",
    "        target_last = target_first\n",
    "    mse_last = calculate_mse(pred_last, target_last)\n",
    "    \n",
    "    if mse_first > 0:\n",
    "        return (mse_first - mse_last) / mse_first\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0052fa2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model', 'test_idx', 'n_epochs', 'train_mse_first', 'train_mse_best',\n",
       "       'train_mae_first', 'train_mae_best', 'train_mape_first',\n",
       "       'train_mape_best', 'test_mse_first', 'test_mse_best', 'test_mae_first',\n",
       "       'test_mae_best', 'test_mape_first', 'test_mape_best',\n",
       "       'train_mse_improvement', 'test_mse_improvement', 'total_time_minutes',\n",
       "       'epoch_train_time', 'one_step_time', 'epoch_total_time',\n",
       "       'speed_epochs_per_minute', 'full_time', 'epoch_test_time_one_step',\n",
       "       'last_loss', 'train_mse_improvement_pct', 'test_mse_improvement_pct'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = analyze_experiments(\"experiments_main\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d58f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assessor = df.groupby('model').mean().drop(['test_idx'], axis=1)\n",
    "\n",
    "assessor.reset_index().to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fd3ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
