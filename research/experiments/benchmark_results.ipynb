{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "608242fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def analyze_experiments(experiments_path: str = \"experiments\", skip_models: list = ['LightGRU']) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze all experiments and create comprehensive pandas table.\n",
    "    \n",
    "    Args:\n",
    "        experiments_path: Path to experiments directory\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with metrics for all experiments\n",
    "    \"\"\"\n",
    "    experiments_path = Path(experiments_path)\n",
    "    \n",
    "    # Collect data from all experiments\n",
    "    all_data = []\n",
    "    \n",
    "    for model_dir in experiments_path.iterdir():\n",
    "        if not model_dir.is_dir() or model_dir.name.startswith('.'):\n",
    "            continue\n",
    "            \n",
    "        model_name = model_dir.name\n",
    "        if model_name in skip_models:\n",
    "            continue\n",
    "        \n",
    "        for test_dir in model_dir.iterdir():\n",
    "            if not test_dir.is_dir() or test_dir.name.startswith('.'):\n",
    "                continue\n",
    "                \n",
    "            test_idx = int(test_dir.name)\n",
    "            \n",
    "            try:\n",
    "                # Load time metrics\n",
    "                time_file = test_dir / 'times.json'\n",
    "                if time_file.exists():\n",
    "                    with open(time_file, 'r') as f:\n",
    "                        time_data = json.load(f)\n",
    "                else:\n",
    "                    time_data = {}\n",
    "                \n",
    "                # Find epoch files and calculate training metrics\n",
    "                epoch_files = sorted([f for f in test_dir.iterdir() \n",
    "                                    if f.name.startswith('epoch_') and f.suffix == '.npy'])\n",
    "                \n",
    "                if epoch_files:\n",
    "                    # Calculate convergence speed\n",
    "                    n_epochs = len(epoch_files)\n",
    "                    first_epoch_data = np.load(epoch_files[0])\n",
    "                    test_target = first_epoch_data[-1, :, 1].flatten()\n",
    "\n",
    "                    min_metrics = 1000\n",
    "                    res_file = ''\n",
    "                    for i, epoch_file in enumerate(epoch_files):\n",
    "                        # Calculate metrics\n",
    "                        last_epoch_data = np.load(epoch_file)\n",
    "                        train_pred_last = last_epoch_data[:-1, :, 0]\n",
    "                        train_target_last = last_epoch_data[:-1, :, 1]\n",
    "                        test_pred_last = last_epoch_data[-1, :, 0].flatten()\n",
    "\n",
    "                        test = 0\n",
    "                        # test += calculate_mse(train_pred_last, train_target_last) / 200\n",
    "                        # test += calculate_mae(test_pred_last, test_target)\n",
    "                        test += calculate_mape(test_pred_last, test_target)\n",
    "                        if test < min_metrics:\n",
    "                            min_metrics = test\n",
    "                            res_file = epoch_file\n",
    "                            n_epochs = i + 1\n",
    "                    \n",
    "                    best_epoch_data = np.load(res_file)\n",
    "                    train_metrics = calculate_epoch_metrics(first_epoch_data, best_epoch_data)\n",
    "                    # Calculate time efficiency\n",
    "                    time_metrics = calculate_time_metrics(time_data, n_epochs)\n",
    "                    \n",
    "                    # Combine all data\n",
    "                    experiment_data = {\n",
    "                        'model': model_name,\n",
    "                        'test_idx': test_idx,\n",
    "                        'n_epochs': n_epochs,\n",
    "                        **train_metrics,\n",
    "                        **time_metrics,\n",
    "                        **time_data  # Add raw time data\n",
    "                    }\n",
    "                    \n",
    "                    all_data.append(experiment_data)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {model_dir.name}/{test_dir.name}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    # Calculate derived metrics if DataFrame is not empty\n",
    "    if not df.empty:\n",
    "        df = calculate_derived_metrics(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_epoch_metrics(first_epoch_data: np.ndarray, last_epoch_data: np.ndarray) -> Dict:\n",
    "    \"\"\"\n",
    "    Calculate training metrics from first and last epoch.\n",
    "    \"\"\"\n",
    "    # Extract predictions and targets\n",
    "    # Shape: [n_tests+1, n_steps, 2] where last dim: 0=predictions, 1=targets\n",
    "    \n",
    "    train_pred_first = first_epoch_data[:-1, :, 0]\n",
    "    train_target_first = first_epoch_data[:-1, :, 1]\n",
    "    \n",
    "    train_pred_last = last_epoch_data[:-1, :, 0]\n",
    "    train_target_last = last_epoch_data[:-1, :, 1]\n",
    "\n",
    "    test_pred_first = first_epoch_data[-1, :, 0].flatten()\n",
    "    test_target = first_epoch_data[-1, :, 1].flatten()\n",
    "    \n",
    "    test_pred_last = last_epoch_data[-1, :, 0].flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        # Training (validation) metrics - improvement from first to last\n",
    "        'train_mse_first': calculate_mse(train_pred_first, train_target_first),\n",
    "        'train_mse_best': calculate_mse(train_pred_last, train_target_last),\n",
    "        'train_mae_first': calculate_mae(train_pred_first, train_target_first),\n",
    "        'train_mae_best': calculate_mae(train_pred_last, train_target_last),\n",
    "        'train_mape_first': calculate_mape(train_pred_first, train_target_first),\n",
    "        'train_mape_best': calculate_mape(train_pred_last, train_target_last),\n",
    "        \n",
    "        # Testing metrics\n",
    "        'test_mse_first': calculate_mse(test_pred_first, test_target),\n",
    "        'test_mse_best': calculate_mse(test_pred_last, test_target),\n",
    "        'test_mae_first': calculate_mae(test_pred_first, test_target),\n",
    "        'test_mae_best': calculate_mae(test_pred_last, test_target),\n",
    "        'test_mape_first': calculate_mape(test_pred_first, test_target),\n",
    "        'test_mape_best': calculate_mape(test_pred_last, test_target),\n",
    "        \n",
    "        # Improvement ratios\n",
    "        'train_mse_improvement': calculate_improvement(train_pred_first, train_pred_last, train_target_first, train_target_last),\n",
    "        'test_mse_improvement': calculate_improvement(test_pred_first, test_pred_last, test_target, None),\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def calculate_time_metrics(time_data: Dict, n_epochs: int) -> Dict:\n",
    "    \"\"\"\n",
    "    Calculate time-related metrics.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    if time_data:\n",
    "        total_time = time_data.get('full_time', 0)\n",
    "        epoch_train_time = time_data.get('epoch_train_time', 0)\n",
    "        one_step_time = time_data.get('epoch_test_time_one_step', 0)\n",
    "        epoch_total_time = total_time / n_epochs\n",
    "        \n",
    "        metrics.update({\n",
    "            'total_time_minutes': total_time / 60,\n",
    "            'epoch_train_time': epoch_train_time,\n",
    "            'one_step_time': one_step_time,\n",
    "            'epoch_total_time': epoch_total_time,\n",
    "            'speed_epochs_per_minute': 60 / epoch_total_time if epoch_total_time > 0 else 0,\n",
    "        })\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def calculate_derived_metrics(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate additional derived metrics.\n",
    "    \"\"\"\n",
    "    # Improvement percentages\n",
    "    df['train_mse_improvement_pct'] = (1 - df['train_mse_best'] / df['train_mse_first']) * 100\n",
    "    df['test_mse_improvement_pct'] = (1 - df['test_mse_best'] / df['test_mse_first']) * 100\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_mse(predictions: np.ndarray, targets: np.ndarray) -> float:\n",
    "    \"\"\"Calculate Mean Squared Error.\"\"\"\n",
    "    return float(np.mean((predictions - targets) ** 2))\n",
    "\n",
    "\n",
    "def calculate_mae(predictions: np.ndarray, targets: np.ndarray) -> float:\n",
    "    \"\"\"Calculate Mean Absolute Error.\"\"\"\n",
    "    return float(np.mean(np.abs(predictions - targets)))\n",
    "\n",
    "\n",
    "def calculate_mape(predictions: np.ndarray, targets: np.ndarray, eps: float = 1e-8) -> float:\n",
    "    \"\"\"Calculate Mean Absolute Percentage Error.\"\"\"\n",
    "    return float(np.mean(np.abs((predictions - targets) / (np.abs(targets) + eps))) * 100)\n",
    "\n",
    "\n",
    "def calculate_improvement(pred_first: np.ndarray, pred_last: np.ndarray, target_first: np.ndarray, target_last: np.ndarray = None) -> float:\n",
    "    \"\"\"Calculate MSE improvement from first to last epoch.\"\"\"\n",
    "    mse_first = calculate_mse(pred_first, target_first)\n",
    "    if target_last is None:\n",
    "        target_last = target_first\n",
    "    mse_last = calculate_mse(pred_last, target_last)\n",
    "    \n",
    "    if mse_first > 0:\n",
    "        return (mse_first - mse_last) / mse_first\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0052fa2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model', 'test_idx', 'n_epochs', 'train_mse_first', 'train_mse_best',\n",
       "       'train_mae_first', 'train_mae_best', 'train_mape_first',\n",
       "       'train_mape_best', 'test_mse_first', 'test_mse_best', 'test_mae_first',\n",
       "       'test_mae_best', 'test_mape_first', 'test_mape_best',\n",
       "       'train_mse_improvement', 'test_mse_improvement', 'total_time_minutes',\n",
       "       'epoch_train_time', 'one_step_time', 'epoch_total_time',\n",
       "       'speed_epochs_per_minute', 'full_time', 'epoch_test_time_one_step',\n",
       "       'last_loss', 'train_mse_improvement_pct', 'test_mse_improvement_pct'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = analyze_experiments(\"experiments\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d58f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assessor = df.groupby('model').mean().drop(['test_idx'], axis=1)\n",
    "\n",
    "assessor.reset_index().to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f227ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>train_mse_first</th>\n",
       "      <th>train_mse_best</th>\n",
       "      <th>train_mae_first</th>\n",
       "      <th>train_mae_best</th>\n",
       "      <th>train_mape_first</th>\n",
       "      <th>train_mape_best</th>\n",
       "      <th>test_mse_first</th>\n",
       "      <th>test_mse_best</th>\n",
       "      <th>test_mae_first</th>\n",
       "      <th>...</th>\n",
       "      <th>total_time_minutes</th>\n",
       "      <th>epoch_train_time</th>\n",
       "      <th>one_step_time</th>\n",
       "      <th>epoch_total_time</th>\n",
       "      <th>speed_epochs_per_minute</th>\n",
       "      <th>full_time</th>\n",
       "      <th>epoch_test_time_one_step</th>\n",
       "      <th>last_loss</th>\n",
       "      <th>train_mse_improvement_pct</th>\n",
       "      <th>test_mse_improvement_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EM_normal_diff</th>\n",
       "      <td>17.5</td>\n",
       "      <td>263.841557</td>\n",
       "      <td>296.333622</td>\n",
       "      <td>11.533698</td>\n",
       "      <td>11.464747</td>\n",
       "      <td>141.170152</td>\n",
       "      <td>132.271613</td>\n",
       "      <td>87.228729</td>\n",
       "      <td>53.400398</td>\n",
       "      <td>7.186141</td>\n",
       "      <td>...</td>\n",
       "      <td>10.065883</td>\n",
       "      <td>1.079006</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>102.055537</td>\n",
       "      <td>1.733319</td>\n",
       "      <td>603.952957</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.021236</td>\n",
       "      <td>-10.073764</td>\n",
       "      <td>34.314042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEM_laplace</th>\n",
       "      <td>17.3</td>\n",
       "      <td>252.806636</td>\n",
       "      <td>295.040392</td>\n",
       "      <td>11.858149</td>\n",
       "      <td>12.016709</td>\n",
       "      <td>177.739101</td>\n",
       "      <td>159.600375</td>\n",
       "      <td>146.970982</td>\n",
       "      <td>62.641869</td>\n",
       "      <td>9.525366</td>\n",
       "      <td>...</td>\n",
       "      <td>15.869710</td>\n",
       "      <td>0.187181</td>\n",
       "      <td>0.008036</td>\n",
       "      <td>195.770936</td>\n",
       "      <td>1.081148</td>\n",
       "      <td>952.182573</td>\n",
       "      <td>0.008036</td>\n",
       "      <td>0.008744</td>\n",
       "      <td>-28.064181</td>\n",
       "      <td>55.085619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEM_normal</th>\n",
       "      <td>18.1</td>\n",
       "      <td>293.397692</td>\n",
       "      <td>323.645966</td>\n",
       "      <td>13.008472</td>\n",
       "      <td>12.961322</td>\n",
       "      <td>198.553974</td>\n",
       "      <td>194.790236</td>\n",
       "      <td>243.340964</td>\n",
       "      <td>100.661437</td>\n",
       "      <td>11.844473</td>\n",
       "      <td>...</td>\n",
       "      <td>13.180856</td>\n",
       "      <td>0.186340</td>\n",
       "      <td>0.006597</td>\n",
       "      <td>75.430065</td>\n",
       "      <td>1.381772</td>\n",
       "      <td>790.851386</td>\n",
       "      <td>0.006597</td>\n",
       "      <td>0.008914</td>\n",
       "      <td>-8.434720</td>\n",
       "      <td>64.112877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEM_student</th>\n",
       "      <td>26.0</td>\n",
       "      <td>267.470449</td>\n",
       "      <td>298.282945</td>\n",
       "      <td>12.205852</td>\n",
       "      <td>12.211025</td>\n",
       "      <td>190.064071</td>\n",
       "      <td>164.230948</td>\n",
       "      <td>200.080984</td>\n",
       "      <td>62.660456</td>\n",
       "      <td>10.515600</td>\n",
       "      <td>...</td>\n",
       "      <td>29.368902</td>\n",
       "      <td>0.187788</td>\n",
       "      <td>0.014196</td>\n",
       "      <td>107.223327</td>\n",
       "      <td>0.887890</td>\n",
       "      <td>1762.134106</td>\n",
       "      <td>0.014196</td>\n",
       "      <td>0.009106</td>\n",
       "      <td>-19.254600</td>\n",
       "      <td>58.500744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                n_epochs  train_mse_first  train_mse_best  train_mae_first  \\\n",
       "model                                                                        \n",
       "EM_normal_diff      17.5       263.841557      296.333622        11.533698   \n",
       "SEM_laplace         17.3       252.806636      295.040392        11.858149   \n",
       "SEM_normal          18.1       293.397692      323.645966        13.008472   \n",
       "SEM_student         26.0       267.470449      298.282945        12.205852   \n",
       "\n",
       "                train_mae_best  train_mape_first  train_mape_best  \\\n",
       "model                                                               \n",
       "EM_normal_diff       11.464747        141.170152       132.271613   \n",
       "SEM_laplace          12.016709        177.739101       159.600375   \n",
       "SEM_normal           12.961322        198.553974       194.790236   \n",
       "SEM_student          12.211025        190.064071       164.230948   \n",
       "\n",
       "                test_mse_first  test_mse_best  test_mae_first  ...  \\\n",
       "model                                                          ...   \n",
       "EM_normal_diff       87.228729      53.400398        7.186141  ...   \n",
       "SEM_laplace         146.970982      62.641869        9.525366  ...   \n",
       "SEM_normal          243.340964     100.661437       11.844473  ...   \n",
       "SEM_student         200.080984      62.660456       10.515600  ...   \n",
       "\n",
       "                total_time_minutes  epoch_train_time  one_step_time  \\\n",
       "model                                                                 \n",
       "EM_normal_diff           10.065883          1.079006       0.004016   \n",
       "SEM_laplace              15.869710          0.187181       0.008036   \n",
       "SEM_normal               13.180856          0.186340       0.006597   \n",
       "SEM_student              29.368902          0.187788       0.014196   \n",
       "\n",
       "                epoch_total_time  speed_epochs_per_minute    full_time  \\\n",
       "model                                                                    \n",
       "EM_normal_diff        102.055537                 1.733319   603.952957   \n",
       "SEM_laplace           195.770936                 1.081148   952.182573   \n",
       "SEM_normal             75.430065                 1.381772   790.851386   \n",
       "SEM_student           107.223327                 0.887890  1762.134106   \n",
       "\n",
       "                epoch_test_time_one_step  last_loss  \\\n",
       "model                                                 \n",
       "EM_normal_diff                  0.004016   0.021236   \n",
       "SEM_laplace                     0.008036   0.008744   \n",
       "SEM_normal                      0.006597   0.008914   \n",
       "SEM_student                     0.014196   0.009106   \n",
       "\n",
       "                train_mse_improvement_pct  test_mse_improvement_pct  \n",
       "model                                                                \n",
       "EM_normal_diff                 -10.073764                 34.314042  \n",
       "SEM_laplace                    -28.064181                 55.085619  \n",
       "SEM_normal                      -8.434720                 64.112877  \n",
       "SEM_student                    -19.254600                 58.500744  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assessor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17fd3ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_mape_best</th>\n",
       "      <th>train_mape_best</th>\n",
       "      <th>test_mse_best</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>total_time_minutes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EM_normal_diff</th>\n",
       "      <td>16.152443</td>\n",
       "      <td>132.271613</td>\n",
       "      <td>53.400398</td>\n",
       "      <td>17.5</td>\n",
       "      <td>10.065883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEM_laplace</th>\n",
       "      <td>28.625259</td>\n",
       "      <td>159.600375</td>\n",
       "      <td>62.641869</td>\n",
       "      <td>17.3</td>\n",
       "      <td>15.869710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEM_normal</th>\n",
       "      <td>14.782695</td>\n",
       "      <td>194.790236</td>\n",
       "      <td>100.661437</td>\n",
       "      <td>18.1</td>\n",
       "      <td>13.180856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEM_student</th>\n",
       "      <td>12.587490</td>\n",
       "      <td>164.230948</td>\n",
       "      <td>62.660456</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.368902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                test_mape_best  train_mape_best  test_mse_best  n_epochs  \\\n",
       "model                                                                      \n",
       "EM_normal_diff       16.152443       132.271613      53.400398      17.5   \n",
       "SEM_laplace          28.625259       159.600375      62.641869      17.3   \n",
       "SEM_normal           14.782695       194.790236     100.661437      18.1   \n",
       "SEM_student          12.587490       164.230948      62.660456      26.0   \n",
       "\n",
       "                total_time_minutes  \n",
       "model                               \n",
       "EM_normal_diff           10.065883  \n",
       "SEM_laplace              15.869710  \n",
       "SEM_normal               13.180856  \n",
       "SEM_student              29.368902  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = assessor[['test_mape_best', 'train_mape_best', 'test_mse_best', 'n_epochs', 'total_time_minutes']]\n",
    "\n",
    "res_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
